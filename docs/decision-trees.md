# ğŸŒ³ Decision Trees: When to Use What Technique

## ğŸ¯ Main Decision Tree

```
I want to fine-tune an LLM
â”œâ”€â”€ What's your experience level?
â”‚   â”œâ”€â”€ Beginner â†’ Start with Basic LoRA
â”‚   â”œâ”€â”€ Intermediate â†’ What's your goal?
â”‚   â”‚   â”œâ”€â”€ Better conversations â†’ Try DPO Training
â”‚   â”‚   â”œâ”€â”€ Domain expertise â†’ Use task-specific datasets
â”‚   â”‚   â”œâ”€â”€ Multiple languages â†’ Use Qwen2.5
â”‚   â”‚   â””â”€â”€ Vision + text â†’ Use Qwen2-VL
â”‚   â””â”€â”€ Advanced â†’ What's your use case?
â”‚       â”œâ”€â”€ Research â†’ Full fine-tuning or high-rank LoRA
â”‚       â”œâ”€â”€ Production â†’ DPO + evaluation pipeline
â”‚       â””â”€â”€ Experimentation â†’ Quick LoRA experiments
```

## ğŸ” Model Selection Decision Tree

### **Step 1: What's Your Hardware?**

**ğŸ“± Google Colab T4 (15GB) or similar**
- âœ… Phi-3 Mini (3.8B) - Best efficiency
- âœ… Llama-3-8B - Best general performance
- âœ… Qwen2.5-7B - Best multilingual
- âœ… Qwen2-VL-7B - Vision-language tasks  
- âŒ Models >20B - Won't fit

**ğŸ’» Mid-range GPU (24GB)**
- âœ… All 7B-8B models
- âœ… GPT-OSS-20B - Advanced reasoning
- âš ï¸ 30B models (tight fit)
- âŒ 70B+ models

**ğŸ–¥ï¸ High-end GPU (40GB+)**
- âœ… All models up to 70B
- âœ… Full precision training
- âœ… Large batch sizes

### **Step 2: What's Your Task?**

**ğŸ“ Text Generation & Creative Writing**
- Best: Llama-3-8B-Instruct
- Alternative: GPT-OSS-20B
- Budget: Phi-3 Mini

**ğŸ’» Code Generation & Programming**
- Best: Phi-3 Mini (specialized for coding)
- Alternative: CodeLlama-7B
- Advanced: GPT-OSS-20B

**ğŸŒ Multilingual Tasks**
- Best: Qwen2.5-7B (29+ languages)
- Alternative: Llama-3-8B
- Specialized: mT5 variants

**ğŸ§® Mathematical Reasoning**
- Best: Qwen2.5-7B (math-optimized)
- Alternative: GPT-OSS-20B
- Specialized: MathCodeT5

**ğŸ–¼ï¸ Vision-Language Tasks**
- Best: Qwen2-VL-7B (image + text)
- Alternative: LLaVA variants
- Specialized: GPT-4V fine-tuned

**ğŸ’¬ Conversational AI**
- Best: Llama-3-8B-Instruct + DPO
- Alternative: Qwen2.5-7B
- Budget: Phi-3 Mini

## âš™ï¸ Technique Selection Decision Tree

### **Fine-Tuning Method Decision**

```python
def choose_finetuning_method(memory_gb, time_budget, quality_need):
    if memory_gb < 16:
        return "LoRA + 4-bit quantization"
    elif time_budget == "fast" and quality_need == "good":
        return "LoRA + Unsloth"
    elif quality_need == "highest":
        return "Full fine-tuning"
    else:
        return "LoRA + 8-bit"
```

### **Training Configuration Decision Tree**

**ğŸ¯ Your Priority?**
- **ğŸ’¾ Memory Efficiency**
  - Use 4-bit quantization
  - LoRA rank: 8-16
  - Batch size: 1
  - Gradient accumulation: 4-8
- **âš¡ Training Speed**
  - Use Unsloth optimizations
  - Mixed precision (fp16/bf16)
  - Higher batch size
  - Gradient checkpointing: False
- **ğŸ¯ Model Quality**
  - Higher LoRA rank: 32-64
  - More training epochs: 3-5
  - Lower learning rate: 1e-4
  - Larger dataset
- **ğŸ’° Cost Efficiency**
  - Use Google Colab
  - Phi-3 Mini model
  - Short training runs
  - 4-bit quantization

## ğŸ“Š Dataset Size Decision Tree

**ğŸ“š How much data do you have?**

**< 100 examples**
- âš ï¸ Too small for good results
- ğŸ’¡ Use few-shot prompting instead
- ğŸ”„ Or augment with synthetic data

**100 - 1,000 examples**
- âœ… Perfect for LoRA fine-tuning
- ğŸ“ Focus on high-quality curation
- â±ï¸ Training time: 10-30 minutes

**1,000 - 10,000 examples**
- âœ… Excellent for most use cases
- ğŸ¯ Can use higher LoRA ranks
- â±ï¸ Training time: 30 minutes - 2 hours

**10,000+ examples**
- âœ… Great for specialized domains
- ğŸ”„ Consider full fine-tuning
- ğŸ“Š Split into train/validation sets
- â±ï¸ Training time: 2+ hours

## ğŸ¨ Use Case Specific Recommendations

### **ğŸ“ Educational Applications**

**Math Tutoring**
- Model: Qwen2.5-7B (math-specialized)
- Method: LoRA + mathematical datasets
- Training: 1,000 problem-solution pairs
- Post-processing: DPO for explanation quality

**Language Learning**
- Model: Qwen2.5-7B (multilingual)
- Method: LoRA + conversation datasets
- Training: Native speaker dialogues
- Evaluation: Fluency + grammar checks

**Code Teaching**
- Model: Phi-3 Mini (code-optimized)
- Method: LoRA + coding instruction datasets
- Training: Code explanation pairs
- Testing: Code generation accuracy

### **ğŸ’¼ Business Applications**

**Customer Service**
- Model: Llama-3-8B + DPO training
- Dataset: Historical support tickets
- Training: Helpful vs unhelpful responses
- Deployment: API with safety filters

**Content Generation**
- Model: GPT-OSS-20B (creativity)
- Method: LoRA + brand voice data
- Training: Company writing samples
- Quality: Human review process

**Data Analysis**
- Model: Qwen2.5-7B (structured data)
- Method: LoRA + analysis examples
- Training: Question-insight pairs
- Output: JSON formatted results

### **ğŸ”¬ Research Applications**

**Vision-Language Research**
- Model: Qwen2-VL-7B
- Method: LoRA + multimodal datasets
- Training: Image-text pairs
- Evaluation: Multimodal benchmarks

**Scientific Literature**
- Model: GPT-OSS-20B (reasoning)
- Method: Full fine-tuning or high-rank LoRA
- Training: Domain-specific papers
- Output: Research insights

## ğŸ”„ Iterative Improvement Decision Tree

**ğŸ¯ After Initial Training**

**Model performance is...**
- **ğŸ˜ Poor (< 60% accuracy)**
  - ğŸ” Check data quality
  - ğŸ“Š Increase dataset size
  - âš™ï¸ Adjust learning rate
  - ğŸ”„ Try different model
- **ğŸ˜ Okay (60-80% accuracy)**
  - ğŸ“ˆ Increase LoRA rank
  - ğŸ¯ Add more training epochs
  - ğŸ”§ Try DPO training
  - ğŸ“š Improve dataset quality
- **ğŸ˜Š Good (80%+ accuracy)**
  - ğŸš€ Ready for deployment!
  - ğŸ“Š Set up evaluation pipeline
  - ğŸ”„ Consider model distillation
  - ğŸ“ˆ Monitor production performance

## ğŸ› ï¸ Quick Decision Flowcharts

### **âš¡ 30-Second Model Choice**

**I need a model for...**
- ğŸ“± Mobile deployment â†’ Phi-3 Mini
- ğŸ’¬ Chatbot â†’ Llama-3-8B + DPO
- ğŸŒ Multiple languages â†’ Qwen2.5-7B
- ğŸ§® Math problems â†’ Qwen2.5-7B
- ğŸ’» Code tasks â†’ Phi-3 Mini
- ğŸ–¼ï¸ Vision + text â†’ Qwen2-VL-7B
- ğŸ”¬ Research â†’ GPT-OSS-20B

### **âš¡ 30-Second Technique Choice**

**I want...**
- ğŸ’¾ Lowest memory â†’ LoRA + 4-bit
- âš¡ Fastest training â†’ LoRA + Unsloth
- ğŸ¯ Best quality â†’ Full fine-tuning
- ğŸ’° Cheapest â†’ LoRA + Colab T4
- ğŸ¤– Better responses â†’ DPO training
- ğŸ–¼ï¸ Vision capabilities â†’ Vision model + LoRA

## ğŸ“‹ Decision Checklist

Before starting fine-tuning, check:

- [ ] **Hardware Requirements**: Can my GPU handle the model?
- [ ] **Dataset Quality**: Do I have clean, relevant data?  
- [ ] **Time Budget**: How long can I train?
- [ ] **Quality Expectations**: What accuracy do I need?
- [ ] **Deployment Target**: Where will this model run?
- [ ] **Budget Constraints**: What can I afford to spend?

## ğŸ¯ Common Decision Scenarios

### **Scenario 1: "I'm a student with limited budget"**
âœ… **Solution:**
- Platform: Google Colab (free)
- Model: Phi-3 Mini
- Method: LoRA + 4-bit quantization
- Dataset: Small, curated dataset
- Time: Quick experiments

### **Scenario 2: "I need production-ready chatbot"** 
âœ… **Solution:**
- Platform: Cloud GPU (Runpod/Lambda)
- Model: Llama-3-8B-Instruct
- Method: SFT + DPO training
- Dataset: Conversational data + preferences
- Evaluation: Human feedback loop

### **Scenario 3: "I want to experiment with techniques"**
âœ… **Solution:**
- Platform: Mixed (Colab + cloud)
- Models: Multiple small models
- Method: Rapid LoRA experiments
- Dataset: Standardized benchmarks
- Focus: Technique comparison

### **Scenario 4: "I need vision-language capabilities"**
âœ… **Solution:**
- Platform: Google Colab T4 or better
- Model: Qwen2-VL-7B
- Method: LoRA + 4-bit quantization
- Dataset: Image-text pairs
- Use case: OCR, VQA, image understanding

## ğŸ“Š Decision Matrix

| Priority | Memory | Speed | Quality | Cost | Recommended Setup |
|----------|--------|--------|---------|------|-------------------|
| **Learning** | Low | Medium | Medium | Low | Phi-3 + LoRA + Colab |
| **Research** | High | Low | High | High | GPT-OSS-20B + Full FT |
| **Production** | Medium | High | High | Medium | Llama-3-8B + DPO |
| **Experimentation** | Low | High | Medium | Low | Multiple small models |
| **Vision Tasks** | Medium | Medium | High | Medium | Qwen2-VL + LoRA |

---

**Still unsure?** â†’ [Ask in Discussions](https://github.com/Abeshith/FineTuning_LanguageModels/discussions) or check [Troubleshooting Guide](./troubleshooting.md)