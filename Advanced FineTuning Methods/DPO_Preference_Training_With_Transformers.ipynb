{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U transformers datasets peft trl bitsandbytes accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cae4xzRiGk5n",
        "outputId": "818cfc0e-b980-483e-8753-8b9ba50abf5a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/511.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.5/465.5 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\""
      ],
      "metadata": {
        "id": "N3iszsWbJPDc"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "unyp3B8GJPeN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "# Path to your zip file\n",
        "zip_path = \"/content/tinyllama-instruction.zip\"\n",
        "\n",
        "# Extract all files\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ],
      "metadata": {
        "id": "-8InH2dCJSBT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/checkpoint-3\""
      ],
      "metadata": {
        "id": "-KWu2LBPJURk"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instruction_model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\")"
      ],
      "metadata": {
        "id": "S-RwZYwOJVm3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Explain how artificial intelligence is improving the process of drug discovery and development in the pharmaceutical industry.\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = instruction_model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=100,\n",
        "    temperature=0.8,\n",
        "    top_p=0.9,\n",
        "    do_sample=True,\n",
        "    repetition_penalty=1.1\n",
        ")\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJJwV3gkJYPC",
        "outputId": "c747fd6f-01fc-4f6a-970c-320e0993d24f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explain how artificial intelligence is improving the process of drug discovery and development in the pharmaceutical industry.\n",
            "Teaching Strategies for AI in Pharmacy: Developing and delivering teaching activities that encourage the use of artificial intelligence (AI) to enhance students' knowledge, skills and understanding will be discussed.\n",
            "Artificial Intelligence: AI has been used in many sectors of our society such as healthcare, manufacturing, education and the military. These applications have created an awareness and interest amongst students that they can apply AI within their care\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import DPOTrainer\n",
        "from transformers import AutoTokenizer,  AutoModelForCausalLM, TrainingArguments\n",
        "from peft import PeftModel\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from datasets import load_dataset\n",
        "import torch"
      ],
      "metadata": {
        "id": "pwJTY5bhJhAU"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\""
      ],
      "metadata": {
        "id": "_eRp_s2vJxA0"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instruction_checkpoint = \"/content/checkpoint-3\""
      ],
      "metadata": {
        "id": "pWVqSB5mJyiy"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"csv\", data_files=\"/content/pharma_preference_data.csv\")[\"train\"]"
      ],
      "metadata": {
        "id": "1ACsL8cnJz9u"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "AKi-vmxKJ1i7"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    bias=\"none\"\n",
        ")"
      ],
      "metadata": {
        "id": "Iufs7xHxJ4rt"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    load_in_8bit=True,\n",
        "    device_map=\"auto\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtSgZUhaJ6s3",
        "outputId": "d6a959e8-16b0-4d99-c36b-854c519ca4bb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = PeftModel.from_pretrained(model, instruction_checkpoint)"
      ],
      "metadata": {
        "id": "IrVVco8QJ-dF"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.merge_and_unload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc8MuziDKAb6",
        "outputId": "1547308d-6d32-4607-85c0-ea3c9c8e2155"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/bnb.py:110: UserWarning: Merge lora module to 8-bit linear may get different generations due to rounding errors.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pref_model_lora = get_peft_model(model, lora_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PEElJVjKB6z",
        "outputId": "fb6467ac-b28d-444a-b1fd-3991568a3b22"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "id": "W4Ia27V2KD5N"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import DPOTrainer, DPOConfig"
      ],
      "metadata": {
        "id": "4wgxIkIZKQou"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dpo_args = DPOConfig(\n",
        "    output_dir=\"./tinyllama-preference-alignment\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=8,\n",
        "    num_train_epochs=1,\n",
        "    beta=0.1,\n",
        "    report_to=None,\n",
        "    logging_dir=None,\n",
        "    loss_type=\"sigmoid\",\n",
        "    remove_unused_columns=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yJsEiY_KSDp",
        "outputId": "7639bb2f-d84b-45b5-c1c2-def7998024fe"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = DPOTrainer(\n",
        "    model=pref_model_lora,\n",
        "    ref_model=None,\n",
        "    args=dpo_args,\n",
        "    train_dataset=dataset,\n",
        "    processing_class=tokenizer,\n",
        ")"
      ],
      "metadata": {
        "id": "U-7882NiKfn_"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "cW0IMj_xKjuh",
        "outputId": "eaf9082e-1996-4bcb-f5f9-a0a3688f41e4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n",
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 00:00, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1, training_loss=0.66193026304245, metrics={'train_runtime': 4.1452, 'train_samples_per_second': 1.206, 'train_steps_per_second': 0.241, 'total_flos': 0.0, 'train_loss': 0.66193026304245, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/checkpoint-3\"\n",
        "instruction_model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\")\n",
        "\n",
        "inputs = tokenizer(question, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = instruction_model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=100,\n",
        "    temperature=0.8,\n",
        "    top_p=0.9,\n",
        "    do_sample=True,\n",
        "    repetition_penalty=1.1\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67jj8Y0uKyPf",
        "outputId": "f185dc65-0bb0-408f-db79-ca1cedc051a7"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explain how Metformin works in the human body and why some researchers believe it could have benefits beyond diabetes treatment.\n",
            "Crohn's disease (CD) is an inflammatory bowel disease that can be severe. Recent research has shown that metformin may reduce the risk of flare-ups in people with CD.\n",
            "What Is Crohn's Disease?\n",
            "Crohn's disease (CD) is a type of inflammatory bowel disease that is characterized by inflammation in the intestinal tract, which can lead to abdom\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/tinyllama-preference-alignment/checkpoint-1\"\n",
        "preference_aligned_model = AutoModelForCausalLM.from_pretrained(model_path, dtype=torch.float16)"
      ],
      "metadata": {
        "id": "-UhIIoH7K7qb"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preference_aligned_model.to(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TlXZ3msLCh9",
        "outputId": "3d849e7d-fd08-4703-b4d3-4e8c5b1768ec"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(32000, 2048)\n",
              "    (layers): ModuleList(\n",
              "      (0-21): 22 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaAttention(\n",
              "          (q_proj): lora.Linear(\n",
              "            (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=2048, out_features=8, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=8, out_features=2048, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
              "          (v_proj): lora.Linear(\n",
              "            (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=2048, out_features=8, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=8, out_features=256, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
              "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
              "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
              "          (act_fn): SiLUActivation()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(question, return_tensors=\"pt\").to(\"cuda\")\n",
        "outputs = preference_aligned_model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=100,\n",
        "    temperature=0.8,\n",
        "    top_p=0.9,\n",
        "    do_sample=True,\n",
        "    repetition_penalty=1.1\n",
        ")\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCzQMXQUK_pS",
        "outputId": "3ab9913b-f7ec-4a38-b5bd-6261df4039ec"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explain how Metformin works in the human body and why some researchers believe it could have benefits beyond diabetes treatment.\n",
            "Metformin, a common diabetes drug used to treat type 2 diabetes, has long been known as a \"fat burner,\" but new research suggests that it may also help prevent cancer.\n",
            "In a review of more than 100 studies published this week in the journal Diabetologia, researchers from Britain's National Health Service (NHS) and Oxford University said metformin may have properties that can be exploited to prevent cancer by:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tJuZaJitLK86"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}